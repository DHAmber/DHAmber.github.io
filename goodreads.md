---
layout: page
title: 
permalink: /goodreads/
---


<p align="center">
Interesting Graph and Machine Learning papers
</p>

### Large Scale Machine learning

"[GraphSAINT Graph Sampling Based Inductive Learning Method](www.openreview.net/pdf?id=BJe8pkHFwS)"
<br>           Zeng et al. -<b> ICLR 2020</b>.
 <br><br>
  <b>Contribution:</b>
  <br>       a. Samples sub-graphs and runs GCN on entire sub-graph without node sampling in layers.
<br>         b. Defined node and edge sampling procedure in order to avoid bias.
  
<br>
<br>




### Combinatorial Optimization

"[Learning Combinatorial Optimization Algorithms over Graphs](https://arxiv.org/abs/1704.01665)"
<br>           Dai et al. -<b> NeurIPS 2017</b>.
 <br><br>
  <b>Contribution:</b>
  <br>       a. GCN + RL End to End framework for Comb Optimization.
  <br>       b. Tackled problems like TSP, Vertex Cover, Set Cover etc.
<br>
<br>
<br>


"[Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search](https://arxiv.org/abs/1810.10659)"
<br>           Lee et al. -<b> NeurIPS 2018</b>.
 <br><br>
  <b>Contribution:</b>
  <br>       a. GCN + Guided Tree Search.
  <br>       b. Parallelizable 
<br>
<br>
<br>


"[Attention, Learn to Solve Routing Problems!](https://arxiv.org/abs/1810.10659)"
<br>           Kool et al. -<b> ICLR 2019</b>.
 <br><br>
  <b>Contribution:</b>
  <br>       a. GCN + Transformer to encode Graph
  <br>       b. Decoder to output sequence of nodes.
<br>

<br>

<br>



### GNN

"[Position-aware Graph Neural Networks](https://arxiv.org/pdf/1906.04817.pdf)"
<br>           You et al. -<b> ICML 2019</b>.
 <br><br>
  <b>Contribution:</b>
  <br>       a. Two nodes, even if they have same neighboorhood get different embeddings. This is not in the case of GraphSage.
<br>         b. Uses Landmark nodes and weighs message from node to landmark nodes using distance to landmark node.
  
<br><br>



 "[Hierarchical Graph Representation Learning with Differentiable Pooling](https://arxiv.org/pdf/1806.08804.pdf)"
<br>           Ying et al. <b></b>.
 <br><br>
  <b>Contribution:</b>
  <br>       a. Aggregates nodes into clusters.
<br>         b. Coarsens clusters into larger level clusters.
  
<br><br>



"[Graph Attention Networks](https://arxiv.org/pdf/1710.10903.pdf)"
<br>           Velickovic et al. -<b> ICLR 2018</b>.
 <br><br>
  <b>Contribution:</b>
  <br>       a. Aggregate neighbor information based upon importance.
<br>         b. Inductive approach/
  <br>
<br>


  
  
"[Inductive Representation Learning on Large Graphs](https://arxiv.org/pdf/1706.02216.pdf)"
<br>           Hamilton et al. -<b> NeurIPS 2017</b>.
 <br><br>
  <b>Contribution:</b>
  <br>      a. Inductive approach
<br>        b. Learns aggregation matrices.
<br>        c. Samples neighorhood uniformly.
<br>
<br>


<br>



### Recommendation Systems using Graphs
"[Graph Convolutional Neural Networks for Web-Scale Recommender Systems](https://arxiv.org/pdf/1806.01973.pdf)"
<br>           Ying et al. -<b> KDD 2018</b>.
 <br><br>
<br>
<br>



"[Session-based Social Recommendation via Dynamic Graph Attention Networks](https://arxiv.org/pdf/1902.09362.pdf)"
<br>           Song et al. -<b> WSDM 2019</b>.
 <br><br>
  <b>Contribution:</b>
  <br>  a. Dynamic user interests and context-dependent social influences.
<br>    b. Attention based modelling
<br><br>
<br>





"[Inductive Matrix Completion Based on Graph Neural Networks](https://openreview.net/forum?id=ByxxgCEYDS)"
<br>           Zhang et al. -<b> ICLR 2020</b>.
 <br><br>
  <b>Contribution:</b>
  <br>  a. Featureless nodes
<br>    b. Localized graph- Perform GCN on localized subgraph for user-movie target pair.

<br>
<br><br>




### Dynamic Networks

"[Multi-task Representation Learning for Travel Time Estimation](https://infolab.usc.edu/DocsDemos/kdd_2018_deep_eta.pdf)"
<br>           Li et al. -<b> KDD 2018</b>.
 <br><br>
  <b>Contribution:</b>
  <br>  a. Multi Task framework to predict travel time using auxillary tasks.
<br>  
<br>
<br>



"[emporal Network Representation Learning viaHistorical Neighborhoods Aggregation](https://arxiv.org/pdf/2003.13212.pdf#cite.zhou2018dynamic)"
<br>           Li et al. -<b> ICDE 2020</b>.
 <br><br>
  <b>Contribution:</b>
  <br>  a. Concept of temporal random walks
  <br>  b. Different weight to different edges based upon timestamp.
  <br>  c. Different weightage to different random walks.
  
  
<br>  





  
